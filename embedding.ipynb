{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb358366",
   "metadata": {},
   "source": [
    "Vecteurs techniques (tools_list + topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138c3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF sauvegard√© : (1349, 4745)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "# --- Charger la DB enrichie ---\n",
    "df = pd.read_json(\"github_data_enriched.jsonl\", lines=True)\n",
    "\n",
    "# --- Construire vocabulaire technique ---\n",
    "all_tech = set()\n",
    "for tools in df['tools_list']:\n",
    "    all_tech.update(tools)\n",
    "for topics in df['topics_list']:\n",
    "    all_tech.update(topics)\n",
    "\n",
    "vocab_list = sorted(list(all_tech))  # ordre fixe\n",
    "\n",
    "repo_texts = df.apply(\n",
    "    lambda row: \" \".join(row[\"tools_list\"] + row[\"topics_list\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tech = vectorizer.fit_transform(repo_texts)\n",
    "\n",
    "# ‚úÖ SAUVEGARDE\n",
    "np.save(\"X_tech.npy\", X_tech.toarray())\n",
    "\n",
    "print(\"TF-IDF sauvegard√© :\", X_tech.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5388cc",
   "metadata": {},
   "source": [
    "Vecteurs s√©mantiques (full_text embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7f311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880d260d6ae34caa8f887234408a46bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings sauvegard√©s : (1349, 384)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device :\", device)\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "df = pd.read_json(\"github_data_enriched.jsonl\", lines=True)\n",
    "texts = df[\"full_text\"].fillna(\"\").tolist()\n",
    "\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "# ‚úÖ SAUVEGARDE\n",
    "np.save(\"embeddings_semantic.npy\", embeddings)\n",
    "\n",
    "print(\"Embeddings sauvegard√©s :\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3216ce0",
   "metadata": {},
   "source": [
    "Vecteurs num√©riques (features suppl√©mentaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf2c9f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features num√©riques sauvegard√©es : (1349, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "numeric_features = df[\n",
    "    [\"log_stars\", \"fork_ratio\", \"recency_days\"]\n",
    "].fillna(0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_numeric = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# ‚úÖ SAUVEGARDE\n",
    "np.save(\"X_numeric.npy\", X_numeric)\n",
    "\n",
    "print(\"Features num√©riques sauvegard√©es :\", X_numeric.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f0968",
   "metadata": {},
   "source": [
    "Vecteur hybride final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bcc8902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Vecteur hybride pr√™t\n",
      "Shape : (1349, 5132)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# üîÑ Charger depuis disque\n",
    "embeddings = np.load(\"embeddings_semantic.npy\")\n",
    "X_tech = csr_matrix(np.load(\"X_tech.npy\"))\n",
    "X_numeric = np.load(\"X_numeric.npy\")\n",
    "\n",
    "# Normalisation\n",
    "embeddings = normalize(embeddings)\n",
    "X_tech = normalize(X_tech)\n",
    "X_numeric = normalize(X_numeric)\n",
    "\n",
    "# Pond√©rations\n",
    "W_SEM = 0.6\n",
    "W_TECH = 0.3\n",
    "W_NUM = 0.1\n",
    "\n",
    "# Fusion\n",
    "X_hybrid = np.hstack([\n",
    "    embeddings * W_SEM,\n",
    "    X_tech.toarray() * W_TECH,\n",
    "    X_numeric * W_NUM\n",
    "])\n",
    "\n",
    "# ‚úÖ SAUVEGARDE FINALE\n",
    "np.save(\"X_hybrid.npy\", X_hybrid)\n",
    "\n",
    "print(\"üî• Vecteur hybride pr√™t\")\n",
    "print(\"Shape :\", X_hybrid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a9f41",
   "metadata": {},
   "source": [
    "Stockage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab389898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dossier de stockage pr√™t : data/processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Dossier principal pour stocker les fichiers\n",
    "DATA_DIR = \"data/processed\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Dossier de stockage pr√™t : {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dcd5387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ M√©tadonn√©es sauvegard√©es : data/processed\\metadata.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger la DB enrichie si pas d√©j√† en m√©moire\n",
    "df = pd.read_json(\"github_data_enriched.jsonl\", lines=True)\n",
    "\n",
    "# S√©lection des colonnes utiles pour stockage\n",
    "metadata_cols = [\n",
    "    \"databaseId\", \"nameWithOwner\", \"url\", \"target_domain\",\n",
    "    \"stargazerCount\", \"forkCount\", \"recency_days\",\n",
    "    \"tools_list\", \"topics_list\"\n",
    "]\n",
    "\n",
    "metadata_df = df[metadata_cols]\n",
    "\n",
    "# Sauvegarde JSONL\n",
    "metadata_file = os.path.join(DATA_DIR, \"metadata.jsonl\")\n",
    "metadata_df.to_json(metadata_file, orient='records', lines=True, force_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ M√©tadonn√©es sauvegard√©es : {metadata_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "355846af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings s√©mantiques sauvegard√©s : data/processed\\embeddings_semantic.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# embeddings : numpy array (N, 384)\n",
    "# exemple : embeddings d√©j√† calcul√©s avec SentenceTransformer\n",
    "# embeddings = model.encode(...)\n",
    "\n",
    "embeddings_file = os.path.join(DATA_DIR, \"embeddings_semantic.npy\")\n",
    "np.save(embeddings_file, embeddings)\n",
    "\n",
    "print(f\"‚úÖ Embeddings s√©mantiques sauvegard√©s : {embeddings_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9526949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vecteurs TF-IDF sauvegard√©s : data/processed\\X_tech.npz\n",
      "‚úÖ Vocabulaire sauvegard√© : data/processed\\vocab_tech.json\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import save_npz\n",
    "\n",
    "# X_tech : matrice sparse\n",
    "# vectorizer.vocabulary_ : dictionnaire vocabulaire\n",
    "\n",
    "# Sauvegarder matrice sparse\n",
    "X_tech_file = os.path.join(DATA_DIR, \"X_tech.npz\")\n",
    "save_npz(X_tech_file, X_tech)\n",
    "\n",
    "# Sauvegarder vocabulaire JSON\n",
    "import json\n",
    "vocab_file = os.path.join(DATA_DIR, \"vocab_tech.json\")\n",
    "with open(vocab_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vectorizer.vocabulary_, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Vecteurs TF-IDF sauvegard√©s : {X_tech_file}\")\n",
    "print(f\"‚úÖ Vocabulaire sauvegard√© : {vocab_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d84c5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Features num√©riques sauvegard√©es : data/processed\\X_numeric.npy\n"
     ]
    }
   ],
   "source": [
    "# X_numeric : numpy array\n",
    "numeric_file = os.path.join(DATA_DIR, \"X_numeric.npy\")\n",
    "np.save(numeric_file, X_numeric)\n",
    "\n",
    "print(f\"‚úÖ Features num√©riques sauvegard√©es : {numeric_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4841fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vecteur hybride sauvegard√© : data/processed\\X_hybrid.npy\n",
      "Shape : (1349, 5132)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Normalisation\n",
    "embeddings_norm = normalize(embeddings)\n",
    "X_tech_norm = normalize(X_tech)\n",
    "X_numeric_norm = normalize(X_numeric)\n",
    "\n",
    "# Pond√©ration (modifiable)\n",
    "W_SEM = 0.6\n",
    "W_TECH = 0.3\n",
    "W_NUM = 0.1\n",
    "\n",
    "X_hybrid = np.hstack([\n",
    "    embeddings_norm * W_SEM,\n",
    "    X_tech_norm.toarray() * W_TECH,\n",
    "    X_numeric_norm * W_NUM\n",
    "])\n",
    "\n",
    "hybrid_file = os.path.join(DATA_DIR, \"X_hybrid.npy\")\n",
    "np.save(hybrid_file, X_hybrid)\n",
    "\n",
    "print(f\"‚úÖ Vecteur hybride sauvegard√© : {hybrid_file}\")\n",
    "print(\"Shape :\", X_hybrid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a21888",
   "metadata": {},
   "source": [
    "FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "812a7fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vecteur hybride charg√©\n",
      "Shape : (1349, 5132)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"data/processed\"\n",
    "hybrid_file = f\"{DATA_DIR}/X_hybrid.npy\"\n",
    "\n",
    "X_hybrid = np.load(hybrid_file)\n",
    "print(\"‚úÖ Vecteur hybride charg√©\")\n",
    "print(\"Shape :\", X_hybrid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9de46b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index FAISS CPU cr√©√©\n",
      "Nombre de vecteurs dans l'index : 1349\n",
      "‚úÖ Index FAISS CPU sauvegard√© : index/faiss_index_cpu.bin\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "d = X_hybrid.shape[1]  # dimension des vecteurs\n",
    "index_cpu = faiss.IndexFlatL2(d)  # distance L2\n",
    "\n",
    "# Ajouter tous les vecteurs\n",
    "index_cpu.add(X_hybrid.astype(np.float32))\n",
    "print(\"‚úÖ Index FAISS CPU cr√©√©\")\n",
    "print(\"Nombre de vecteurs dans l'index :\", index_cpu.ntotal)\n",
    "\n",
    "# Sauvegarder l'index\n",
    "faiss.write_index(index_cpu, \"index/faiss_index_cpu.bin\")\n",
    "print(\"‚úÖ Index FAISS CPU sauvegard√© : index/faiss_index_cpu.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4724db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index FAISS CPU cr√©√©\n",
      "Nombre de vecteurs dans l'index : 1349\n",
      "‚úÖ Index FAISS sauvegard√© : index/faiss_index_cpu.bin\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np  # je suppose que X_hybrid est un np.array\n",
    "\n",
    "# Dimension des vecteurs\n",
    "d = X_hybrid.shape[1]\n",
    "\n",
    "# Cr√©er l'index FAISS CPU (compatible Windows)\n",
    "index_flat = faiss.IndexFlatL2(d)\n",
    "\n",
    "# Ajouter les vecteurs\n",
    "index_flat.add(X_hybrid.astype(np.float32))\n",
    "print(\"‚úÖ Index FAISS CPU cr√©√©\")\n",
    "print(\"Nombre de vecteurs dans l'index :\", index_flat.ntotal)\n",
    "\n",
    "# Sauvegarder l'index CPU\n",
    "faiss.write_index(index_flat, \"index/faiss_index_cpu.bin\")\n",
    "print(\"‚úÖ Index FAISS sauvegard√© : index/faiss_index_cpu.bin\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
